{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport os\nimport sys\nimport glob\nimport torch\nimport torchvision\n\nimport numpy as np\nimport datetime as dt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import transforms, datasets, models\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\n\n%matplotlib inline\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.438614,"end_time":"2021-03-29T11:50:48.533762","exception":false,"start_time":"2021-03-29T11:50:47.095148","status":"completed"},"tags":[],"id":"HUl4fAsYltEP","execution":{"iopub.status.busy":"2023-05-19T21:21:10.224108Z","iopub.execute_input":"2023-05-19T21:21:10.224913Z","iopub.status.idle":"2023-05-19T21:21:14.700245Z","shell.execute_reply.started":"2023-05-19T21:21:10.224875Z","shell.execute_reply":"2023-05-19T21:21:14.699346Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_path = \"../input/ammi-2021-convnets/\"\ntrain_path = join(data_path, \"train/train\")\ntest_path = join(data_path,\"test/test\")\nextraimage_path = join(data_path, \"extraimages/extraimages\")","metadata":{"papermill":{"duration":0.021142,"end_time":"2021-03-29T11:50:48.566314","exception":false,"start_time":"2021-03-29T11:50:48.545172","status":"completed"},"tags":[],"id":"ylUQduBJltEQ","execution":{"iopub.status.busy":"2023-05-19T21:21:16.353453Z","iopub.execute_input":"2023-05-19T21:21:16.354725Z","iopub.status.idle":"2023-05-19T21:21:16.361265Z","shell.execute_reply.started":"2023-05-19T21:21:16.354682Z","shell.execute_reply":"2023-05-19T21:21:16.360065Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['KAGGLE_USERNAME'] = 'muhirwasalomon'\nos.environ['KAGGLE_KEY'] = 'f2e155be15e51da2a38317f327c0669b'\n!kaggle competitions download -c ammi-2023-convnets --force\n!unzip -q ammi-2023-convnets.zip -d ammi-2023-convnets\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GM3oUZsIltER","outputId":"ae702af6-633d-45f6-911f-2435a505a099","execution":{"iopub.status.busy":"2023-05-19T21:21:17.923052Z","iopub.execute_input":"2023-05-19T21:21:17.923398Z","iopub.status.idle":"2023-05-19T21:22:38.678005Z","shell.execute_reply.started":"2023-05-19T21:21:17.923368Z","shell.execute_reply":"2023-05-19T21:22:38.676660Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading ammi-2023-convnets.zip to /kaggle/working\n100%|█████████████████████████████████████▉| 2.30G/2.30G [00:58<00:00, 43.9MB/s]\n100%|██████████████████████████████████████| 2.30G/2.30G [00:58<00:00, 42.4MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = 'ammi-2023-convnets/train/train'\ntest_path = 'ammi-2023-convnets/test/test'\n","metadata":{"id":"YmpIE7ARltER","execution":{"iopub.status.busy":"2023-05-19T21:22:46.015441Z","iopub.execute_input":"2023-05-19T21:22:46.016422Z","iopub.status.idle":"2023-05-19T21:22:46.021624Z","shell.execute_reply.started":"2023-05-19T21:22:46.016382Z","shell.execute_reply":"2023-05-19T21:22:46.020523Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom sklearn.utils import class_weight\nfrom collections import Counter\ntorch.random.seed()\n# Define the transformations\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(size=224),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(degrees=30),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(255),\n    transforms.RandomResizedCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Compute class weights\ndef compute_class_weights(labels):\n    label_counts = Counter(labels)\n    class_weights = [1.0 / label_counts[label] for label in labels]\n    return torch.tensor(class_weights, dtype=torch.float)\n\nclass CassavaDataset(Dataset):\n    def __init__(self, path, transform=None):\n        self.classes = os.listdir(path)\n        self.path = [f\"{path}/{className}\" for className in self.classes]\n        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n        self.transform = transform\n\n        files = []\n        for i, className in enumerate(self.classes):\n            for fileName in self.file_list[i]:\n                files.append([i, fileName])\n        self.file_list = files\n\n        # Compute class weights\n        labels = [item[0] for item in self.file_list]\n        self.class_weights = compute_class_weights(labels)\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        fileName = self.file_list[idx][1]\n        classCategory = self.file_list[idx][0]\n        im = Image.open(fileName)\n\n        if self.transform:\n            im = self.transform(im)\n\n        return im, classCategory\n","metadata":{"id":"I8cMKd7UMRA5","execution":{"iopub.status.busy":"2023-05-19T21:22:50.458658Z","iopub.execute_input":"2023-05-19T21:22:50.459236Z","iopub.status.idle":"2023-05-19T21:22:50.473859Z","shell.execute_reply.started":"2023-05-19T21:22:50.459202Z","shell.execute_reply":"2023-05-19T21:22:50.472827Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data = CassavaDataset(train_path, transform=train_transform)\ntest_data = CassavaDataset(test_path, transform=test_transform)","metadata":{"id":"cjyFub42T4eW","execution":{"iopub.status.busy":"2023-05-19T21:22:51.583029Z","iopub.execute_input":"2023-05-19T21:22:51.583373Z","iopub.status.idle":"2023-05-19T21:22:51.645335Z","shell.execute_reply.started":"2023-05-19T21:22:51.583347Z","shell.execute_reply":"2023-05-19T21:22:51.644405Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nvalidation_split = 0.2\nrandom_seed = 42\nshuffle_dataset = True  # Define shuffle_dataset variable here\n\n# Creating data indices for training and validation splits\ndataset_size = len(train_data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\n\nif shuffle_dataset:\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]\n","metadata":{"id":"ZN21b7BbltES","execution":{"iopub.status.busy":"2023-05-19T21:22:52.609049Z","iopub.execute_input":"2023-05-19T21:22:52.609736Z","iopub.status.idle":"2023-05-19T21:22:52.730884Z","shell.execute_reply.started":"2023-05-19T21:22:52.609696Z","shell.execute_reply":"2023-05-19T21:22:52.729933Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"batch_size=8","metadata":{"id":"wRx_UhpGlxq8","execution":{"iopub.status.busy":"2023-05-19T21:22:54.163596Z","iopub.execute_input":"2023-05-19T21:22:54.163981Z","iopub.status.idle":"2023-05-19T21:22:54.170219Z","shell.execute_reply.started":"2023-05-19T21:22:54.163952Z","shell.execute_reply":"2023-05-19T21:22:54.168600Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import SubsetRandomSampler, DataLoader\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\nval_loader = DataLoader(train_data, batch_size=batch_size, sampler=val_sampler)\ntest_loader = DataLoader(test_data, batch_size=batch_size)\n","metadata":{"id":"DT0LEPV3ltES","execution":{"iopub.status.busy":"2023-05-19T21:22:57.373376Z","iopub.execute_input":"2023-05-19T21:22:57.373748Z","iopub.status.idle":"2023-05-19T21:22:57.381740Z","shell.execute_reply.started":"2023-05-19T21:22:57.373721Z","shell.execute_reply":"2023-05-19T21:22:57.379654Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\n# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"YHkHGaQ4ltET","execution":{"iopub.status.busy":"2023-05-19T21:22:58.103314Z","iopub.execute_input":"2023-05-19T21:22:58.104793Z","iopub.status.idle":"2023-05-19T21:22:58.175374Z","shell.execute_reply.started":"2023-05-19T21:22:58.104754Z","shell.execute_reply":"2023-05-19T21:22:58.174330Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.models import resnet18\n\n# Define the ResNet-based model\nclass ResNetClassifier(nn.Module):\n    def __init__(self, num_classes, weight_decay=0.0001):\n        super(ResNetClassifier, self).__init__()\n        # Load the pre-trained ResNet50 model\n        self.resnet = resnet18(pretrained=True)\n        \n        # Modify the last fully-connected layer for the desired number of classes\n        num_features = self.resnet.fc.in_features\n        self.resnet.fc = nn.Linear(num_features, num_classes)\n        \n        # Define the weight decay (L2 regularization) for the parameters\n        self.weight_decay = weight_decay\n\n    def forward(self, input):\n        x = self.resnet(input)\n        return x\n\nmodel = ResNetClassifier(num_classes=5)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.RMSprop(model.parameters(), lr=0.0002, weight_decay=model.weight_decay)\n","metadata":{"id":"Eo8mfPNCltET","execution":{"iopub.status.busy":"2023-05-19T21:23:06.165376Z","iopub.execute_input":"2023-05-19T21:23:06.165761Z","iopub.status.idle":"2023-05-19T21:23:09.804731Z","shell.execute_reply.started":"2023-05-19T21:23:06.165731Z","shell.execute_reply":"2023-05-19T21:23:09.801701Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 228MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"Ake3uiLHlMO8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #weights initialization\n# def initalize_weights(m):\n#     classname = m.__class__.__name__\n#     if classname.find('Conv') != -1:\n#         nn.init.normal_(m.weight.data, 0.0, 0.02) #Initialize the weights to mean=0, sd=0.02\n#     elif classname.find('BatchNorm') != -1:\n#         nn.init.normal_(m.weight.data, 1.0, 0.02)\n#         nn.init.constant_(m.bias.data, 0)","metadata":{"id":"itc4nwY3ojxu","execution":{"iopub.status.busy":"2023-05-19T21:23:10.433632Z","iopub.execute_input":"2023-05-19T21:23:10.434291Z","iopub.status.idle":"2023-05-19T21:23:10.439882Z","shell.execute_reply.started":"2023-05-19T21:23:10.434259Z","shell.execute_reply":"2023-05-19T21:23:10.438952Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def reset_model_parameters(model):\n    \"\"\"Reset the parameters of a PyTorch model.\"\"\"\n    for param in model.parameters():\n        if param.requires_grad:\n            param.data.uniform_(-0.1, 0.1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T21:23:11.298534Z","iopub.execute_input":"2023-05-19T21:23:11.299200Z","iopub.status.idle":"2023-05-19T21:23:11.305299Z","shell.execute_reply.started":"2023-05-19T21:23:11.299169Z","shell.execute_reply":"2023-05-19T21:23:11.304250Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import KFold\n# def train(model, criterion, train_data, optimizer, num_epochs, num_folds):\n#     \"\"\"Train a model using cross-validation.\"\"\"\n#     kf = KFold(n_splits=num_folds, shuffle=True)\n\n#     print('----- Cross-validation Loop -----')\n#     # Loop over folds.\n#     for fold, (train_indices, val_indices) in enumerate(kf.split(train_data)):\n#         print(f'Fold: {fold + 1}')\n\n# #         # Reset model parameters for each fold.\n# #         model = ResNetClassifier(5) \n# #         model.reset_model_parameters()\n\n#         # Exponential moving average of the loss.\n#         ema_loss = None\n\n#         print('----- Training Loop -----')\n\n#         # Get the training data and targets for the current fold.\n#         fold_train_data = [train_data[idx] for idx in train_indices]\n\n#         # Create a dataloader for the training data.\n#         fold_train_loader = DataLoader(fold_train_data, batch_size=batch_size, shuffle=True)\n\n#         # Loop over epochs.\n#         for epoch in range(num_epochs):\n#             # Training phase\n#             model.train()\n\n#             # Loop over training data.\n#             for batch_idx, (features, target) in enumerate(fold_train_loader):\n#                 # Move data to the device.\n#                 features = features.to(device)\n#                 target = target.to(device)\n\n#                 # Forward pass.\n#                 output = model(features)\n#                 loss = criterion(output, target)\n\n#                 # Backward pass.\n#                 optimizer.zero_grad()\n#                 loss.backward()\n#                 optimizer.step()\n\n#                 # Update exponential moving average of the loss.\n#                 if ema_loss is None:\n#                     ema_loss = loss.item()\n#                 else:\n#                     ema_loss += (loss.item() - ema_loss) * 0.01\n\n#             # Print training progress at the end of the epoch.\n#             print('Fold: {} \\tEpoch: {} \\tTraining Loss: {:.3f}'.format(fold + 1, epoch, ema_loss))\n","metadata":{"papermill":{"duration":0.024895,"end_time":"2021-03-29T11:50:49.499328","exception":false,"start_time":"2021-03-29T11:50:49.474433","status":"completed"},"tags":[],"id":"STGB7v9RltET","execution":{"iopub.status.busy":"2023-05-19T21:23:12.484005Z","iopub.execute_input":"2023-05-19T21:23:12.484681Z","iopub.status.idle":"2023-05-19T21:23:12.491240Z","shell.execute_reply.started":"2023-05-19T21:23:12.484640Z","shell.execute_reply":"2023-05-19T21:23:12.490315Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom copy import deepcopy\n\ndef train(model, criterion, train_data, optimizer, num_epochs, num_folds, patience):\n    \"\"\"Train a model using cross-validation.\"\"\"\n    kf = KFold(n_splits=num_folds, shuffle=True)\n    \n    print('----- Cross-validation Loop -----')\n    # Loop over folds.\n    for fold, (train_indices, val_indices) in enumerate(kf.split(train_data)):\n        print(f'Fold: {fold + 1}')\n\n        # Reset model parameters for each fold.\n        #model.apply(reset_parameters)\n        \n        # Exponential moving average of the loss.\n        ema_loss = None\n        \n        best_loss = float('inf')\n        counter = 0\n\n        print('----- Training Loop -----')\n\n        # Get the training and validation data for the current fold.\n        fold_train_data = [train_data[idx] for idx in train_indices]\n        fold_val_data = [train_data[idx] for idx in val_indices]\n\n        # Create data loaders for training and validation data.\n        fold_train_loader = DataLoader(fold_train_data, batch_size=batch_size, shuffle=True)\n        fold_val_loader = DataLoader(fold_val_data, batch_size=batch_size, shuffle=False)\n\n        # Loop over epochs.\n        for epoch in range(num_epochs):\n            # Training phase\n            model.train()\n\n            # Loop over training data.\n            for batch_idx, (features, target) in enumerate(fold_train_loader):\n                # Move data to the device.\n                features = features.to(device)\n                target = target.to(device)\n\n                # Forward pass.\n                output = model(features)\n                loss = criterion(output, target)\n\n                # Backward pass.\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n\n                # Update exponential moving average of the loss.\n                if ema_loss is None:\n                    ema_loss = loss.item()\n                else:\n                    ema_loss += (loss.item() - ema_loss) * 0.01\n\n            # Print training progress at the end of the epoch.\n            print('Fold: {} \\tEpoch: {} \\tTraining Loss: {:.3f}'.format(fold + 1, epoch, ema_loss))\n            \n            # Validation phase\n            model.eval()\n            val_loss = 0.0\n            \n            with torch.no_grad():\n                for val_features, val_target in fold_val_loader:\n                    val_features = val_features.to(device)\n                    val_target = val_target.to(device)\n                    \n                    val_output = model(val_features)\n                    val_loss += criterion(val_output, val_target).item()\n            \n            val_loss /= len(fold_val_loader)\n            \n            # Check if the current validation loss is the best so far\n            if val_loss < best_loss:\n                best_loss = val_loss\n                best_model = deepcopy(model)\n                counter = 0\n            else:\n                counter += 1\n            \n            # Check if the training should be stopped early\n#             if counter >= patience:\n#                 print('Early stopping! No improvement in validation loss for {} epochs.'.format(patience))\n#                 break\n        \n        # Set the best model as the final model for this fold\n        model = best_model\n\ndef reset_parameters(module):\n    \"\"\"Reset the parameters of a module.\"\"\"\n    if hasattr(module, 'reset_parameters'):\n        module.reset_parameters()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T21:23:13.293849Z","iopub.execute_input":"2023-05-19T21:23:13.294207Z","iopub.status.idle":"2023-05-19T21:23:13.309430Z","shell.execute_reply.started":"2023-05-19T21:23:13.294179Z","shell.execute_reply":"2023-05-19T21:23:13.308516Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def test(model, data_loader):\n    \"\"\"Measures the accuracy of a model on a data set.\"\"\"\n    # Make sure the model is in evaluation mode.\n    model.eval()\n    correct = 0\n    print('----- Model Evaluation -----')\n    # We do not need to maintain intermediate activations while testing.\n    with torch.no_grad():\n\n        # Loop over test data.\n        for features, target in data_loader:\n\n            # Move data to the device.\n            features = features.to(device)\n            target = target.to(device)\n\n            # Forward pass.\n            output = model(features)\n\n            # Get the label corresponding to the highest predicted probability.\n            pred = output.argmax(dim=1, keepdim=True)\n\n            # Move tensors to the same device as the model.\n            pred = pred.to(device)\n            target = target.to(device)\n\n            # Count number of correct predictions.\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    # Print test accuracy.\n    percent = 100. * correct / len(val_sampler)\n    print(f'Test accuracy: {correct} / {len(data_loader.dataset)} ({percent:.0f}%)')\n    torch.save(model.state_dict(), 'model.ckpt')\n    return percent\n","metadata":{"papermill":{"duration":0.024848,"end_time":"2021-03-29T11:50:49.536153","exception":false,"start_time":"2021-03-29T11:50:49.511305","status":"completed"},"tags":[],"id":"YF4yBlZgltEU","execution":{"iopub.status.busy":"2023-05-19T21:23:14.458553Z","iopub.execute_input":"2023-05-19T21:23:14.458925Z","iopub.status.idle":"2023-05-19T21:23:14.468025Z","shell.execute_reply.started":"2023-05-19T21:23:14.458898Z","shell.execute_reply":"2023-05-19T21:23:14.466523Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# def test(model, data_loader):\n#     \"\"\"Measures the accuracy of a model on a data set.\"\"\"\n#     # Make sure the model is in evaluation mode.\n#     model.eval()\n#     correct = 0\n#     total = 0\n\n#     print('----- Model Evaluation -----')\n#     # We do not need to maintain intermediate activations while testing.\n#     with torch.no_grad():\n#         # Loop over test data.\n#         for features, target in data_loader:\n#             # Move data to the device.\n#             features = features.to(device)\n#             target = target.to(device)\n\n#             # Forward pass.\n#             output = model(features)\n\n#             # Get the label corresponding to the highest predicted probability.\n#             _, predicted = torch.max(output.data, 1)\n\n#             # Count number of correct predictions.\n#             total += target.size(0)\n#             correct += (predicted == target).sum().item()\n\n#     # Calculate test accuracy.\n#     accuracy = 100 * correct / total\n#     print(f'Test accuracy: {correct} / {total} ({accuracy:.2f}%)')\n\n#     return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T21:23:15.263555Z","iopub.execute_input":"2023-05-19T21:23:15.264395Z","iopub.status.idle":"2023-05-19T21:23:15.270294Z","shell.execute_reply.started":"2023-05-19T21:23:15.264356Z","shell.execute_reply":"2023-05-19T21:23:15.269088Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Define the number of epochs and patience\nnum_epochs = 15\npatience = 3\n\n# Train the model using cross-validation\ntrain(model, criterion, train_data, optimizer, num_epochs, num_folds=5, patience=patience)\n\n# Evaluate the model on the validation set\nval_accuracy = test(model, val_loader)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXoZGg2opKdw","outputId":"ac2e8aa9-2cea-4441-e9ad-2906a67811ce","execution":{"iopub.status.busy":"2023-05-19T21:23:16.109724Z","iopub.execute_input":"2023-05-19T21:23:16.110367Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"----- Cross-validation Loop -----\nFold: 1\n----- Training Loop -----\nFold: 1 \tEpoch: 0 \tTraining Loss: 1.060\nFold: 1 \tEpoch: 1 \tTraining Loss: 0.862\nFold: 1 \tEpoch: 2 \tTraining Loss: 0.719\nFold: 1 \tEpoch: 3 \tTraining Loss: 0.589\nFold: 1 \tEpoch: 4 \tTraining Loss: 0.440\nFold: 1 \tEpoch: 5 \tTraining Loss: 0.358\nFold: 1 \tEpoch: 6 \tTraining Loss: 0.259\nFold: 1 \tEpoch: 7 \tTraining Loss: 0.224\nFold: 1 \tEpoch: 8 \tTraining Loss: 0.185\nFold: 1 \tEpoch: 9 \tTraining Loss: 0.173\nFold: 1 \tEpoch: 10 \tTraining Loss: 0.159\nFold: 1 \tEpoch: 11 \tTraining Loss: 0.133\nFold: 1 \tEpoch: 12 \tTraining Loss: 0.105\nFold: 1 \tEpoch: 13 \tTraining Loss: 0.110\nFold: 1 \tEpoch: 14 \tTraining Loss: 0.096\nFold: 2\n----- Training Loop -----\nFold: 2 \tEpoch: 0 \tTraining Loss: 0.837\nFold: 2 \tEpoch: 1 \tTraining Loss: 0.816\nFold: 2 \tEpoch: 2 \tTraining Loss: 0.838\nFold: 2 \tEpoch: 3 \tTraining Loss: 0.847\nFold: 2 \tEpoch: 4 \tTraining Loss: 0.861\nFold: 2 \tEpoch: 5 \tTraining Loss: 0.824\nFold: 2 \tEpoch: 6 \tTraining Loss: 0.795\nFold: 2 \tEpoch: 7 \tTraining Loss: 0.834\nFold: 2 \tEpoch: 8 \tTraining Loss: 0.836\nFold: 2 \tEpoch: 9 \tTraining Loss: 0.838\nFold: 2 \tEpoch: 10 \tTraining Loss: 0.857\nFold: 2 \tEpoch: 11 \tTraining Loss: 0.814\nFold: 2 \tEpoch: 12 \tTraining Loss: 0.854\nFold: 2 \tEpoch: 13 \tTraining Loss: 0.815\nFold: 2 \tEpoch: 14 \tTraining Loss: 0.751\nFold: 3\n----- Training Loop -----\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# test(model, test_loader)","metadata":{"papermill":{"duration":0.024454,"end_time":"2021-03-29T12:00:25.51629","exception":false,"start_time":"2021-03-29T12:00:25.491836","status":"completed"},"tags":[],"id":"N2M4fnG9ltEU","execution":{"iopub.status.busy":"2023-05-19T10:41:28.679381Z","iopub.status.idle":"2023-05-19T10:41:28.680071Z","shell.execute_reply.started":"2023-05-19T10:41:28.679814Z","shell.execute_reply":"2023-05-19T10:41:28.679837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom os import listdir\nfrom PIL import Image\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import transforms\n\n# Step 1\ntest_directory = \"ammi-2023-convnets/test/test/0\"\npredictions, test_image_fileName = [], []\n\n# Step 2\n# Process image\ndef preprocess_image(image):\n    image = image.resize((224, 224))\n    image = transforms.ToTensor()(image)\n    image = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(image)\n    return image\n\n# Step 3\ndef predict(image, model):\n    # Pass the image through the model\n    output = model(image.to(device))\n    # Reverse the log function of the output\n    output = torch.exp(output)\n    # Get the predicted class\n    _, predicted_class = output.max(1)\n    return predicted_class.item()\n\n# Step 4\n# Get the list of class names\nclass_names = train_loader.dataset.classes\n\n# Step 5\ntry:\n    # Iterate over the test images\n    test_images = listdir(test_directory)\n    for image_name in test_images:\n        # Check if the item is not a directory\n        if not os.path.isdir(os.path.join(test_directory, image_name)):\n            # Get the image path\n            image_path = os.path.join(test_directory, image_name)\n            print(f\"Preprocess image: {image_path}\")\n            \n            # Open and preprocess the image\n            image = Image.open(image_path)\n            image = preprocess_image(image)\n            image = image.unsqueeze(0).to(device)\n            \n            # Perform the prediction on the image\n            with torch.no_grad():\n                top_class = predict(image, model)\n                # Add the predicted class and image name to the list\n                predictions.append(class_names[top_class])\n                test_image_fileName.append(image_name)\n                # Print the prediction result for the image\n                print(f\"Prediction for image {image_path}: {class_names[top_class]}\")\n\n    # Sort predictions and image filenames based on predictions\n    sorted_predictions, sorted_filenames = zip(*sorted(zip(predictions, test_image_fileName)))\n    predictions = list(sorted_predictions)\n    test_image_fileName = list(sorted_filenames)\n\nexcept Exception as e:\n    # Handle any exceptions that occur during the process\n    print(e)\n","metadata":{"papermill":{"duration":0.024454,"end_time":"2021-03-29T12:00:25.51629","exception":false,"start_time":"2021-03-29T12:00:25.491836","status":"completed"},"tags":[],"id":"uK8iNi3IltEU","execution":{"iopub.status.busy":"2023-05-19T10:41:28.681340Z","iopub.status.idle":"2023-05-19T10:41:28.682010Z","shell.execute_reply.started":"2023-05-19T10:41:28.681767Z","shell.execute_reply":"2023-05-19T10:41:28.681790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make submission here","metadata":{"papermill":{"duration":0.023453,"end_time":"2021-03-29T12:00:25.554652","exception":false,"start_time":"2021-03-29T12:00:25.531199","status":"completed"},"tags":[],"id":"AGt1k3DtltEU","execution":{"iopub.status.busy":"2023-05-19T10:41:28.683252Z","iopub.status.idle":"2023-05-19T10:41:28.683934Z","shell.execute_reply.started":"2023-05-19T10:41:28.683689Z","shell.execute_reply":"2023-05-19T10:41:28.683713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nsubmission_data = {\"Category\": predictions, \"Id\": test_image_fileName}\nsubmission_data_frame = pd.DataFrame(submission_data)\n\n# Save the DataFrame to CSV\nsubmission_data_frame.to_csv('/kaggle/working/submission_file5.csv', index=False)\n","metadata":{"papermill":{"duration":0.01493,"end_time":"2021-03-29T12:00:25.584744","exception":false,"start_time":"2021-03-29T12:00:25.569814","status":"completed"},"tags":[],"id":"S0hXfromltEU","execution":{"iopub.status.busy":"2023-05-19T10:41:28.685183Z","iopub.status.idle":"2023-05-19T10:41:28.685866Z","shell.execute_reply.started":"2023-05-19T10:41:28.685622Z","shell.execute_reply":"2023-05-19T10:41:28.685645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nsubmission_data = {\"Category\": predictions, \"Id\": test_image_fileName}\nsubmission_data_frame = pd.DataFrame(submission_data)\n\n# Save the DataFrame to CSV\nsubmission_data_frame.to_csv('/kaggle/working/submission_file4.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T10:41:28.687080Z","iopub.status.idle":"2023-05-19T10:41:28.687775Z","shell.execute_reply.started":"2023-05-19T10:41:28.687529Z","shell.execute_reply":"2023-05-19T10:41:28.687552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}